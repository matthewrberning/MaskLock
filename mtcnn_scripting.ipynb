{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mtcnn\n",
    "import cv2\n",
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\OI\\anaconda3\\envs\\MaskLock_py37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"C:/Users/OI/Desktop/test_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = detector.detect_faces(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [331, 162, 233, 315], 'confidence': 0.9991043210029602, 'keypoints': {'left_eye': (428, 277), 'right_eye': (530, 286), 'nose': (501, 335), 'mouth_left': (431, 401), 'mouth_right': (513, 407)}}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'box': [331, 162, 233, 315],\n",
       " 'confidence': 0.9991043210029602,\n",
       " 'keypoints': {'left_eye': (428, 277),\n",
       "  'right_eye': (530, 286),\n",
       "  'nose': (501, 335),\n",
       "  'mouth_left': (431, 401),\n",
       "  'mouth_right': (513, 407)}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[331, 162, 233, 315]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_box = result[0][\"box\"]\n",
    "result[0][\"box\"]\n",
    "\n",
    "#bounding_box[0] is the x coordinate of the top left corner\n",
    "#bounding_box[1] is the y coordinate of the top left corner\n",
    "#bounding_box[2] is the width of the box\n",
    "#bounding_box[3] is the height of the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top left coords: (331, 162)\n",
      "bottom left coords: (331, 477)\n",
      "top right coords: (564, 162)\n",
      "bottom right coords: (564, 477)\n"
     ]
    }
   ],
   "source": [
    "# cv2.rectangle(image,\n",
    "#               (bounding_box[0], bounding_box[1]),\n",
    "#               (bounding_box[0]+bounding_box[2], bounding_box[1]+bounding_box[3]),\n",
    "#               (24, 8, 255), #rgb color\n",
    "#               2 #line thickness\n",
    "#              )\n",
    "\n",
    "#top left corner\n",
    "print(f\"top left coords: ({bounding_box[0]}, {bounding_box[1]})\")\n",
    "image = cv2.circle(image, (bounding_box[0], bounding_box[1]), 10, (255, 0, 0), 2)\n",
    "\n",
    "#bottom left corner (x coord of top left)(y coord of top left + height)\n",
    "print(f\"bottom left coords: ({bounding_box[0]}, {bounding_box[1]+bounding_box[3]})\")\n",
    "image = cv2.circle(image, (bounding_box[0], bounding_box[1]+bounding_box[3]), 10, (255, 255, 0), 2)\n",
    "\n",
    "#top right corner (x coord of top left plus width)(y coord of top left)\n",
    "print(f\"top right coords: ({bounding_box[0]+bounding_box[2]}, {bounding_box[1]})\")\n",
    "image = cv2.circle(image, (bounding_box[0]+bounding_box[2], bounding_box[1]), 10, (0, 255, 0), 2)\n",
    "\n",
    "#bottom right corner (x coord of top left plus width)(y coord of top left + height)\n",
    "print(f\"bottom right coords: ({bounding_box[0]+bounding_box[2]}, {bounding_box[1]+bounding_box[3]})\")\n",
    "image = cv2.circle(image, (bounding_box[0]+bounding_box[2], bounding_box[1]+bounding_box[3]), 10, (0, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite(\"C:/Users/OI/Desktop/test_1_bounding_box.jpg\", image)\n",
    "# cv2.namedWindow(\"image\")\n",
    "# cv2.imshow(\"image\", image)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundingbox(face, width, height, scale=1.3, minsize=None):\n",
    "    x1 = face.left()\n",
    "    y1 = face.top()\n",
    "    x2 = face.right()\n",
    "    y2 = face.bottom()\n",
    "    size_bb = int(max(x2 - x1, y2 - y1) * scale)\n",
    "    if minsize:\n",
    "        if size_bb < minsize:\n",
    "            size_bb = minsize\n",
    "    center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "    # Check for out of bounds, x-y top left corner\n",
    "    x1 = max(int(center_x - size_bb // 2), 0)\n",
    "    y1 = max(int(center_y - size_bb // 2), 0)\n",
    "    # Check for too big bb size for given x, y\n",
    "    size_bb = min(width - x1, size_bb)\n",
    "    size_bb = min(height - y1, size_bb)\n",
    "\n",
    "    return x1, y1, size_bb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'box': [237, 261, 63, 79], 'confidence': 0.9999973773956299, 'keypoints': {'left_eye': (255, 290), 'right_eye': (285, 291), 'nose': (269, 308), 'mouth_left': (255, 321), 'mouth_right': (281, 323)}}, {'box': [671, 285, 41, 53], 'confidence': 0.9999858140945435, 'keypoints': {'left_eye': (684, 305), 'right_eye': (705, 305), 'nose': (695, 316), 'mouth_left': (685, 327), 'mouth_right': (702, 327)}}, {'box': [904, 292, 33, 44], 'confidence': 0.9998931884765625, 'keypoints': {'left_eye': (915, 309), 'right_eye': (931, 308), 'nose': (924, 317), 'mouth_left': (915, 325), 'mouth_right': (931, 325)}}, {'box': [898, 170, 43, 53], 'confidence': 0.9998337030410767, 'keypoints': {'left_eye': (911, 191), 'right_eye': (932, 192), 'nose': (921, 202), 'mouth_left': (911, 212), 'mouth_right': (929, 213)}}, {'box': [679, 428, 33, 40], 'confidence': 0.9998231530189514, 'keypoints': {'left_eye': (688, 444), 'right_eye': (705, 443), 'nose': (697, 452), 'mouth_left': (689, 459), 'mouth_right': (705, 458)}}, {'box': [18, 276, 49, 57], 'confidence': 0.9997953772544861, 'keypoints': {'left_eye': (33, 297), 'right_eye': (58, 297), 'nose': (46, 307), 'mouth_left': (35, 319), 'mouth_right': (56, 320)}}, {'box': [670, 188, 47, 57], 'confidence': 0.9997938275337219, 'keypoints': {'left_eye': (682, 210), 'right_eye': (705, 210), 'nose': (692, 222), 'mouth_left': (683, 234), 'mouth_right': (701, 235)}}, {'box': [897, 62, 39, 55], 'confidence': 0.9996059536933899, 'keypoints': {'left_eye': (906, 83), 'right_eye': (927, 83), 'nose': (916, 95), 'mouth_left': (907, 104), 'mouth_right': (925, 104)}}, {'box': [679, 33, 43, 54], 'confidence': 0.9995381832122803, 'keypoints': {'left_eye': (694, 55), 'right_eye': (715, 55), 'nose': (705, 67), 'mouth_left': (694, 74), 'mouth_right': (714, 75)}}, {'box': [571, 529, 38, 52], 'confidence': 0.9990035891532898, 'keypoints': {'left_eye': (582, 550), 'right_eye': (601, 549), 'nose': (592, 557), 'mouth_left': (585, 570), 'mouth_right': (600, 570)}}, {'box': [28, 146, 42, 53], 'confidence': 0.9989845156669617, 'keypoints': {'left_eye': (40, 168), 'right_eye': (61, 167), 'nose': (50, 180), 'mouth_left': (42, 189), 'mouth_right': (61, 188)}}, {'box': [270, 39, 34, 42], 'confidence': 0.9989757537841797, 'keypoints': {'left_eye': (281, 54), 'right_eye': (298, 56), 'nose': (288, 64), 'mouth_left': (280, 71), 'mouth_right': (294, 73)}}, {'box': [474, 176, 36, 46], 'confidence': 0.9987578392028809, 'keypoints': {'left_eye': (488, 194), 'right_eye': (506, 196), 'nose': (498, 205), 'mouth_left': (485, 209), 'mouth_right': (502, 212)}}, {'box': [910, 409, 39, 47], 'confidence': 0.9985631108283997, 'keypoints': {'left_eye': (921, 426), 'right_eye': (939, 427), 'nose': (928, 438), 'mouth_left': (920, 445), 'mouth_right': (936, 445)}}, {'box': [240, 407, 42, 54], 'confidence': 0.9983918070793152, 'keypoints': {'left_eye': (253, 429), 'right_eye': (273, 430), 'nose': (262, 442), 'mouth_left': (253, 451), 'mouth_right': (271, 451)}}, {'box': [470, 421, 34, 44], 'confidence': 0.9979133009910583, 'keypoints': {'left_eye': (480, 439), 'right_eye': (497, 440), 'nose': (487, 451), 'mouth_left': (480, 458), 'mouth_right': (494, 459)}}, {'box': [232, 172, 53, 65], 'confidence': 0.9969918727874756, 'keypoints': {'left_eye': (248, 199), 'right_eye': (274, 196), 'nose': (264, 214), 'mouth_left': (253, 223), 'mouth_right': (275, 221)}}, {'box': [468, 38, 43, 56], 'confidence': 0.9954366087913513, 'keypoints': {'left_eye': (481, 60), 'right_eye': (502, 60), 'nose': (491, 70), 'mouth_left': (481, 81), 'mouth_right': (500, 82)}}, {'box': [430, 274, 49, 58], 'confidence': 0.9912753105163574, 'keypoints': {'left_eye': (446, 299), 'right_eye': (470, 296), 'nose': (460, 310), 'mouth_left': (449, 321), 'mouth_right': (471, 318)}}, {'box': [24, 38, 36, 46], 'confidence': 0.9829450249671936, 'keypoints': {'left_eye': (35, 55), 'right_eye': (53, 55), 'nose': (44, 67), 'mouth_left': (37, 74), 'mouth_right': (52, 75)}}, {'box': [111, 86, 21, 25], 'confidence': 0.8733419179916382, 'keypoints': {'left_eye': (118, 93), 'right_eye': (128, 96), 'nose': (122, 100), 'mouth_left': (116, 104), 'mouth_right': (123, 106)}}]\n"
     ]
    }
   ],
   "source": [
    "# width, height = image.shape()\n",
    "# get_boundingbox(result, width, height)\n",
    "\n",
    "test = \"2\"\n",
    "test_pic = f\"C:/Users/OI/Desktop/test_{test}.png\"\n",
    "image_raw = cv2.imread(test_pic)\n",
    "\n",
    "#set up face detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# #use first face detected and check if there were none\n",
    "result = detector.detect_faces(image_raw)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO MANY FACES!!! ..or not enough!? :O\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "# read in image with cv2\n",
    "test = \"b\"\n",
    "test_pic = f\"C:/Users/OI/Desktop/test_{test}.png\"\n",
    "image_raw = cv2.imread(test_pic)\n",
    "\n",
    "#convert to greyscale\n",
    "image = cv2.cvtColor(image_raw, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "#set up face detector\n",
    "# face_detector = dlib.get_frontal_face_detector()\n",
    "detector = MTCNN()\n",
    "\n",
    "# #use first face detected and check if there were none\n",
    "result = detector.detect_faces(image_raw)\n",
    "# faces = face_detector(gray, 1)\n",
    "# if len(faces) == 0:\n",
    "if len(result) == 0 or len(result) > 1:\n",
    "    print(\"TOO MANY FACES!!! ..or not enough!? :O\")\n",
    "    sys.exit(0)\n",
    "# #     return None\n",
    "\n",
    "# face = faces[0]\n",
    "bounding_box = result[0][\"box\"]\n",
    "\n",
    "#collect image height and width\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "#set scaling factor\n",
    "scale=0.95\n",
    "\n",
    "#collect coordinates of bounding box\n",
    "# x1 = face.left()\n",
    "x1 = bounding_box[0]\n",
    "print(\"x1: \", x1)\n",
    "\n",
    "# y1 = face.top()\n",
    "y1 = bounding_box[1]\n",
    "print(\"y1: \", y1)\n",
    "\n",
    "# x2 = face.right()\n",
    "x2 = bounding_box[0]+bounding_box[2]\n",
    "print(\"x2: \", x2)\n",
    "\n",
    "# y2 = face.bottom()\n",
    "y2 = bounding_box[1]+bounding_box[3]\n",
    "print(\"y2: \", y2)\n",
    "\n",
    "print()\n",
    "cv2.circle(image,(x1, y1), 10, (0,155,255), 8) #x coord of top left, y coord of top left => Top Left Corner\n",
    "print(f\"top left coords: ({x1}, {y1})\")\n",
    "\n",
    "cv2.circle(image,(x1, y2), 10, (255,0,0), 8) #x coord of top left, y coord of bottom left => Bottom Left Corner\n",
    "print(f\"bottom left coords: ({x1}, {y2})\")\n",
    "\n",
    "cv2.circle(image,(x2, y1), 10, (255,0,255), 8) #x coord of bottom right, y coord of top left => Upper Right Corner\n",
    "print(f\"top right coords: ({x2}, {y1})\")\n",
    "\n",
    "cv2.circle(image,(x2, y2), 10, (0,255,0), 8) #x coord of bottom right, y coord of bottom left => Bottom Right Corner\n",
    "print(f\"bottom right coords: ({x2}, {y2})\")\n",
    "\n",
    "#save copy of bounding boxed image\n",
    "cv2.imwrite(f\"C:/Users/OI/Desktop/test_{test}_bb.png\", image)\n",
    "print()\n",
    "\n",
    "#scale bounding box?\n",
    "size_bb = int(max(x2 - x1, y2 - y1) * scale)\n",
    "print(\"size_bb 1: \", size_bb)\n",
    "\n",
    "# if minsize:\n",
    "#     if size_bb < minsize:\n",
    "#         size_bb = minsize\n",
    "center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "# Check for out of bounds, x-y top left corner\n",
    "x1 = max(int(center_x - size_bb // 2), 0)\n",
    "y1 = max(int(center_y - size_bb // 2), 0)\n",
    "\n",
    "# Check for too big bb size for given x, y\n",
    "size_bb = min(width - x1, size_bb)\n",
    "print(\"size_bb 2: \", size_bb)\n",
    "size_bb = min(height - y1, size_bb)\n",
    "print(\"size_bb 3: \", size_bb)\n",
    "\n",
    "# set up for crop with slicing\n",
    "x, y, size = x1, y1, size_bb\n",
    "cropped_face = image[y:y + size, x:x + size]\n",
    "\n",
    "#save copy of cropped image\n",
    "cv2.imwrite(f\"C:/Users/OI/Desktop/test_{test}_crop.png\", cropped_face)\n",
    "\n",
    "output_image_size=224\n",
    "\n",
    "resized_image = cv2.resize(cropped_face, (output_image_size, output_image_size))\n",
    "\n",
    "#save copy of resized image\n",
    "cv2.imwrite(f\"C:/Users/OI/Desktop/test_{test}_resized.png\", resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
